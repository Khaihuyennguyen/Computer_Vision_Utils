{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# from dataPath import DATA_PATH\n",
    "# from dataPath import MODEL_PATH\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "matplotlib.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFile =  \"ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\"\n",
    "configFile =  \"ssd_mobilenet_v2_coco_2018_03_29.pbtxt\"\n",
    "classFile =  \"coco_class_labels.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and input image to memory\n",
    "# Detect objects using the foward method of the network\n",
    "# Display the detected objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Tensorflow Model\n",
    "Read the model specified above to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\" in function 'ReadProtoFromBinaryFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromTensorflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigFile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\" in function 'ReadProtoFromBinaryFile'\n"
     ]
    }
   ],
   "source": [
    "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(classFile) as fb:\n",
    "    labels = fb.read().split(\"\\n\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect objects\n",
    "\n",
    "The below function takes in the network and images\n",
    "it first preprocessed the input image and then passes it through the network using forward function\n",
    "\n",
    "Finally it returns the detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each file in the directory\n",
    "\n",
    "def detect_objects(net, im):\n",
    "    # Blob dimensions (dimxdim)\n",
    "    dim = 300\n",
    "    \n",
    "    mean = (127.5, 127.5, 127.5)\n",
    "    \n",
    "    # Create a blob from the image\n",
    "    blob = cv2.dnn.blobFromImage(im, 1.0/127.5, (dim, dim), mean, True)\n",
    "    \n",
    "    # Pass blob to the network\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Perform Prediction\n",
    "    objects = net.forward()\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ulitiy function used for displaying the objects Name on the images\n",
    "def display_text(im, text, x, y):\n",
    "    # Get text size\n",
    "    textSize = cv2.getTextSize(text, FONTFACE, FONT_SCALE, THICKNESS)\n",
    "    dim = textSize[0]\n",
    "    baseline = textSize[1]\n",
    "    \n",
    "    # use text size to craete a black rectangle\n",
    "    cv2.rectangle(im, (x,y-dim[1] - baseline), (x + dim[0],y + baseline), (0,0,0), cv2.FILLED);\n",
    "    # Display text inside the rectangle\n",
    "    cv2.putText(im, text, (x, y-5 ), FONTFACE, FONT_SCALE, (0, 255, 255), THICKNESS, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#his function gets the objects returned from the above function and loops through all the detected objects and draws bounding box around each detected object. It also uses the above utility functions for displaying the class name of the detected object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTFACE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.7\n",
    "THICKNESS = 1\n",
    "\n",
    "def display_objects(im, objects, threshold = 0.25):\n",
    "    \n",
    "    rows = im.shape[0]; cols = im.shape[1]\n",
    "    \n",
    "    # For every Detected objec\n",
    "    for i in range(objects.shape[2]):\n",
    "        # Find the class and confidence\n",
    "        classId = int(objects[0,0,i,1])\n",
    "        score = float(objects[0,0,i,2])\n",
    "        \n",
    "        # Recover original cordinates from normalized coordinates\n",
    "        x = int(objects[0,0,i,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
